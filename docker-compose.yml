services:
  webapp:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_APP=webapp.py
      - FLASK_ENV=production
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama
    # To run a model like gemma3:1b, 
    # use 'docker exec -it werkzeugkaestchen-ollama-1 ollama run gemma3:1b' 
    # after the service is up.
    # check for container name of ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama

volumes:
  ollama:
